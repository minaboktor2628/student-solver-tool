\section{Background}
The process of assigning student staff to courses in the Computer Science department has historically relied on manual coordination. At the beginning of each term, Prof.~Ahrens distributes preference sheets to both Peer Learning Assistants (PLAs) and Teaching Assistants (TAs). These sheets allow student staff to indicate their course preferences, availability, and in some cases their perceived strengths or prior experience with specific material. At the same time, instructors often communicate their own needs and preferences for staff, including desired skill sets or requests for particular individuals. Once collected, these data sources are manually entered into spreadsheets, which then form the foundation for constructing staff assignments. From this point forward, the entire process depends on the coordinator’s ability to reconcile preferences, staffing requirements, and course enrollments by hand. Professor Ahrens must cross reference student availability with instructor needs, ensure that no student is double booked, and balance workloads across the pool of available staff. Course enrollments add another dimension: staffing estimates must account for projected class sizes, which often fluctuate until close to the start of the term. As the number of students and courses in the department continues to grow, these manual checks become increasingly difficult to perform accurately. This workflow places a substantial burden on the coordinator. Because every constraint must be tracked mentally or in ad-hoc spreadsheet formulas, the process becomes time-consuming and error-prone. Small mistakes—such as failing to notice a conflict in availability or overlooking a staffing shortfall in a large-enrollment course—can propagate into serious logistical problems once the term begins. Moreover, the lack of automated validation means that mistakes often go undetected until late in the process, forcing last-minute schedule changes or reassignments that disrupt both students and instructors. In effect, the coordinator plays a high-stakes puzzle game each term, attempting to satisfy a large set of shifting constraints with only spreadsheets and personal oversight. These challenges directly motivate the need for a validator. Before pursuing a fully automated solver, it is essential to establish a system that can check the correctness of existing manual assignments. The validator fills this role by reading in the current spreadsheet artifacts, analyzing them against a defined set of rules, and reporting any violations or inconsistencies. By catching errors early, it reduces the likelihood of conflicts making it through to the final schedule. It also provides the coordinator with greater confidence in the correctness of assignments without requiring significant changes to the existing workflow. Equally important, grounding the first iteration of the project in validation allows the department to adopt new tooling gradually. Because the validator operates directly on the same Excel files already used in the manual process, there is no immediate need to redesign how preferences are collected or how data is managed. Instead, the validator integrates smoothly with the established workflow, offering immediate value while laying the groundwork for more ambitious features such as guided debugging, persistent student and instructor profiles, and automated constraint solving in future iterations. In this way, the background and limitations of the old workflow directly shaped the scope and design of the Ahrens Validator’s initial development.
